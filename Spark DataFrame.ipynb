{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic tutorial of Spark DataFrame with PySpark\n",
    "More about Spark SQL and DataFrame here: https://spark.apache.org/docs/latest/sql-getting-started.html\n",
    "\n",
    "### Import and load spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "sc = SparkContext('local', 'spark_dataframe')\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to create a DataFrame?\n",
    "\n",
    "A DataFrame in Apache Spark can be created in multiple ways:\n",
    "\n",
    "+ It can be created using different data formats. For example, loading the data from JSON, CSV.\n",
    "+ Loading data from Existing RDD.\n",
    "+ Programmatically specifying schema\n",
    "\n",
    "![title](DataFrame-in-Spark.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create from RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "|age|    name|\n",
      "+---+--------+\n",
      "| 25|   Ankit|\n",
      "| 22|Jalfaizy|\n",
      "| 20| saurabh|\n",
      "| 26|    Bala|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "l = [('Ankit',25),('Jalfaizy',22),('saurabh',20),('Bala',26)]\n",
    "rdd = sc.parallelize(l)\n",
    "people = rdd.map(lambda x: Row(name=x[0], age=int(x[1])))\n",
    "people_df = sqlContext.createDataFrame(people)\n",
    "people_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Creating from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+--------------------+-----+\n",
      "|year| make|model|             comment|blank|\n",
      "+----+-----+-----+--------------------+-----+\n",
      "|2012|Tesla|    S|          No comment| null|\n",
      "|1997| Ford| E350|Go get one now th...| null|\n",
      "|2015|Chevy| Volt|                null| null|\n",
      "+----+-----+-----+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('code/data/cars.csv')\n",
    "csv_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read using csv function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+--------------------+-----+\n",
      "|year| make|model|             comment|blank|\n",
      "+----+-----+-----+--------------------+-----+\n",
      "|2012|Tesla|    S|          No comment| null|\n",
      "|1997| Ford| E350|Go get one now th...| null|\n",
      "|2015|Chevy| Volt|                null| null|\n",
      "+----+-----+-----+--------------------+-----+\n",
      "\n",
      "root\n",
      " |-- year: string (nullable = true)\n",
      " |-- make: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- comment: string (nullable = true)\n",
      " |-- blank: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = sqlContext.read.csv('code/data/cars.csv', header=True)\n",
    "df1.show()\n",
    "\n",
    "# check datatype\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Show 2st rows of dataframw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(year=2012, make='Tesla', model='S', comment='No comment', blank=None),\n",
       " Row(year=1997, make='Ford', model='E350', comment='Go get one now they are going fast', blank=None)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Show column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['year', 'make', 'model', 'comment', 'blank']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Statistics description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----+-----+--------------------+-----+\n",
      "|summary|             year| make|model|             comment|blank|\n",
      "+-------+-----------------+-----+-----+--------------------+-----+\n",
      "|  count|                3|    3|    3|                   2|    0|\n",
      "|   mean|           2008.0| null| null|                null| null|\n",
      "| stddev|9.643650760992955| null| null|                null| null|\n",
      "|    min|             1997|Chevy| E350|Go get one now th...| null|\n",
      "|    max|             2015|Tesla| Volt|          No comment| null|\n",
      "+-------+-----------------+-----+-----+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Select column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "| make|model|\n",
      "+-----+-----+\n",
      "|Tesla|    S|\n",
      "| Ford| E350|\n",
      "|Chevy| Volt|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df.select('make','model').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+----------+-----+\n",
      "|year| make|model|   comment|blank|\n",
      "+----+-----+-----+----------+-----+\n",
      "|2012|Tesla|    S|No comment| null|\n",
      "+----+-----+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df.filter(csv_df['year']==2012).show() ## <=> df.filter('year==2012').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Map a select result to RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Tesla', 'S', 1), ('Ford', 'E350', 1), ('Chevy', 'Volt', 1)]\n"
     ]
    }
   ],
   "source": [
    "rdd_make = csv_df.select('make','model').rdd.map(lambda x: (x[0], x[1], 1))\n",
    "print(rdd_make.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sort by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+--------------------+-----+\n",
      "|year| make|model|             comment|blank|\n",
      "+----+-----+-----+--------------------+-----+\n",
      "|1997| Ford| E350|Go get one now th...| null|\n",
      "|2012|Tesla|    S|          No comment| null|\n",
      "|2015|Chevy| Volt|                null| null|\n",
      "+----+-----+-----+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df.orderBy(csv_df.year).show()  # csv_df.orderBy(csv_df.year.desc()).show()  to descease sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apply function during select and add new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+--------------------+-----+--------+\n",
      "|year| make|model|             comment|blank|year_old|\n",
      "+----+-----+-----+--------------------+-----+--------+\n",
      "|2012|Tesla|    S|          No comment| null|       7|\n",
      "|1997| Ford| E350|Go get one now th...| null|      22|\n",
      "|2015|Chevy| Volt|                null| null|       4|\n",
      "+----+-----+-----+--------------------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year,current_date\n",
    "csv_df.withColumn('year_old', year(current_date()) - csv_df.year).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### drop a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+--------------------+-----+\n",
      "|year| make|model|             comment|blank|\n",
      "+----+-----+-----+--------------------+-----+\n",
      "|2012|Tesla|    S|          No comment| null|\n",
      "|1997| Ford| E350|Go get one now th...| null|\n",
      "|2015|Chevy| Volt|                null| null|\n",
      "+----+-----+-----+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_df.drop('year_old').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aggregation with groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|    name|count|\n",
      "+--------+-----+\n",
      "|    Bala|    1|\n",
      "|Jalfaizy|    1|\n",
      "| saurabh|    1|\n",
      "|   Ankit|    1|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people_df.groupby('name').count().show()  ## <=> people_df.groupby('name').agg('count').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running SQL Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "|age|    name|\n",
      "+---+--------+\n",
      "| 25|   Ankit|\n",
      "| 22|Jalfaizy|\n",
      "| 20| saurabh|\n",
      "| 26|    Bala|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert dataframe to view first\n",
    "people_df.createOrReplaceTempView(\"people_view\")\n",
    "# then query\n",
    "sqlContext.sql(\"SELECT * FROM people_view\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
